{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af675ed",
   "metadata": {},
   "source": [
    "# Hypothesis tests with pyhf\n",
    "\n",
    "This notebook will provide you with the tools to do sensitivity estimates which can be used for search region optimization or sensitivity projections.\n",
    "\n",
    "## p-value for discovery of a new signal\n",
    "\n",
    "In searches for new physics we want to know how significant a potential deviation from our Standard Model (SM) expectation is. We do this by a hypothesis test where we try to exclude the SM (\"background only\") hypothesis. We use a so called **p-value** $p_0$ for this, abstractly defined by:\n",
    "\n",
    "$$p_0 = \\int\\limits_{t_\\mathrm{obs}}^{\\infty}p(t|H_0)\\mathrm{d}t$$\n",
    "\n",
    "where $t$ is a test statistic (a number we calculate from our data observations) and $p(t|H_0)$ is the probability distribution for $t$ under the assumption of our **null Hypothesis** $H_0$, in this case the background only hypothesis. This p-value is then typically converted into a number of standard deviations $z$, the **significance** (\"number of sigmas\") via the inverse of the cumulative standard normal distribution $\\Phi$:\n",
    "\n",
    "$$z = \\Phi^{-1}(1 - p)$$\n",
    "\n",
    "The typical convention for particle physics is to speak of *evidence* when $z>3$ and of an *observation* when $z>5$.\n",
    "\n",
    "So what do we use for $t$? We want to use something that discriminates well between our null Hypothesis and an **alternative Hypothesis** that we have in mind. When we try to discover new physics, our null Hypothesis is the absence and the alternative Hypothesis the presence of a signal. We can parametrize this by a **signal strength** parameter $\\mu$. The test statistics used in almost all LHC searches use the **profile likelihood ratio**\n",
    "\n",
    "$$\\Lambda_\\mu = \\frac{L(\\mu, \\hat{\\hat{\\theta}})}{L(\\hat{\\mu}, \\hat{\\theta})}$$\n",
    "\n",
    "where $\\theta$ are the other parameters of our model that are not part of the test, the so called **nuisance parameters**. In contrast, the parameter that we want to test, $\\mu$, is called our **parameter of interest** (POI). The nuisance parameters include all fit parameters, like normalization factors and parameters for describing uncertainties. $L(\\mu, \\hat{\\hat{\\theta}})$ is the Likelihood function, maximized under the condition that our parameter of interest takes the value $\\mu$ and $L(\\hat{\\mu}, \\hat{\\theta})$ is the unconditionally maximized Likelihood. So roughly speaking, we are calculating the fraction of the maximum possible likelihood that we can get under our test condition. If it is high, that speaks for our hypothesis, if it is low, against. The test statistic $t_\\mu$ is then defined as\n",
    "\n",
    "$$t_\\mu = -2\\ln\\Lambda_\\mu$$\n",
    "\n",
    "giving us a test statistic where **high values speak against the null hypothesis**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question 7a:</b> If we want to discover a new signal (using the p-value $p_0$), which value of $\\mu$ are we testing against? Or in other words, what is our null Hypothesis?\n",
    "</div>\n",
    "\n",
    "All that's left now is to know the distribution of $p(t_\\mu|H_0)$. [Wilk's theorem](https://en.wikipedia.org/wiki/Wilks%27_theorem) tells us that the distribution of $t_\\mu$ is asymptotically (for large sample sizes) a chi-square distribution. For the discovery p-value we use a slightly modified version of test statistic, called $q_0$ where $\\hat{\\mu}$ is required to be $>=0$ ($q_0=0$ for $\\hat{\\mu} < 0$). For $q_0$ the p-value in the asymptotic limit collapses to a very simple formula:\n",
    "\n",
    "$$p_0 = \\sqrt{q_0}$$\n",
    "\n",
    "The asymptotic limit often matches quite well even for fairly small sample sizes, but it should be kept in mind this is an approximation. Alternatively, one can evaluate $p(t_\\mu|H_0)$ by Monte Carlo sampling (\"toys\").\n",
    "\n",
    "## CLs for exclusion of an absent signal\n",
    "\n",
    "Now, sadly, not all searches find evidence for new physics. What we still can do in such a case is to try exclude models by rejecting the hypothesis of a signal being present. That usually means we test against $\\mu=1$ or some other value $>0$. The rest of the procedure is very similar with one small detail worth mentioning ... In high energy physics it is very common to use a quantity called $CL_s$ instead of plain p-value. It is defined by\n",
    "\n",
    "$$CL_s = \\frac{CL_{s+b}}{CL_{b}}$$\n",
    "\n",
    "where $CL_{s+b}$ is the p-value for rejecting the hypothesis of signal + background being present (what would be the \"normal\" p-value) and $CL_{b}$ is the p-value for rejecting the background only hypothesis, but now using the test statistic for $\\mu=1$ (so this is different from $p_0$!). We won't go into further details how to calculate those p-values. `pyhf` has the formulas included and does it automatically for us. The asymptotic distributions for all different variants are described in the paper \"Asymptotic formulae for likelihood-based tests of new physics\" ([arXiv:1007.1727](https://arxiv.org/abs/1007.1727)).\n",
    "\n",
    "Just a qualitative explanation of why we use $CL_s$ instead of the p-value: We want to avoid excluding signals in cases where we don't have sensitivity, but observe an *underfluctuation* of the data. In these cases $CL_{s+b}$ and $CL_b$ will be very similar and consequently lead to a large value of $CL_{s}$, telling us the signal is **not** excluded. In case our observations are exactly on spot with the background expectations $CL_b = 0.5$ in the asymptotic limit, so on average we have twice as high \"p-values\" with $CL_s$.\n",
    "\n",
    "The typical convention for particle physics is to speak of an **exclusion** of a signal if $CL_s < 0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59665ed7",
   "metadata": {},
   "source": [
    "## Discovery or exclusion of a signal for a cut & count experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f5e53",
   "metadata": {},
   "source": [
    "Let's start with a simple case where we only want to count the number of events in a certain search region. We assume a certain number of expected background events `b`, expected signal events `s` and a total uncertainty on the expected background `delta_b` ($\\sigma_b$).\n",
    "\n",
    "The likelihood function for this can be formulated as a primary measurement of `n` events and a control (\"auxiliary\") measurment of `m` events that constrains our background parameter within the uncertainty. So, a product of 2 Poisson distributions:\n",
    "\n",
    "$$L(s, b) = \\mathrm{Pois}(n|s + b)\\cdot \\mathrm{Pois}(m|\\tau b)$$\n",
    "\n",
    "The parameter $\\tau$ can be given in terms of $\\sigma_b$ by asking the question \"How much more events do i have to measure in the control region to get the relative uncertainty $\\sigma_b / b$\". That gives\n",
    "\n",
    "$\\tau = \\frac{b}{\\sigma_b^2}$\n",
    "\n",
    "Equivalently, we can replace $b$ by $\\gamma b$ and $s$ by $\\mu s$ to fit normalization factors (initialized to 1) and keep $s$ and $b$ fixed to our expectation.\n",
    "\n",
    "$$L'(\\mu, \\gamma) = L(\\mu s, \\gamma b)$$\n",
    "\n",
    "`pyhf` has a convenience function to create the specification for such a model: `pyhf.simplemodels.hepdata_like`. It also works for arbitrary many bins, but for now let's go with one bin and 5 expected background events, 7 expected signal events and an uncertainty of 2 on the expected background events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba6b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhf\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228261b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 7\n",
    "b = 5\n",
    "delta_b = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyhf.simplemodels.hepdata_like(\n",
    "    signal_data=[s], bkg_data=[b], bkg_uncerts=[delta_b]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa899d5",
   "metadata": {},
   "source": [
    "The model comes with a \"parameter of interest\" (POI) called `mu` that is our signal strength:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.poi_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b97a03",
   "metadata": {},
   "source": [
    "In addition, we have one nuisance parameter, the constrained background normalization $\\gamma$, called `uncorr_bkguncrt` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef213234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.par_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d2d63",
   "metadata": {},
   "source": [
    "It's initial value should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ba4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_initial = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd3e23",
   "metadata": {},
   "source": [
    "So the expected data in our model scales with `mu`. For `mu=1` we get `5 * 1 * 7 = 12`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.expected_actualdata([1, gamma_initial])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88b2ef",
   "metadata": {},
   "source": [
    "for `mu=2` we get `5 + 2 * 7 = 19`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aadd1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.expected_actualdata([2, gamma_initial])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d6b6d9",
   "metadata": {},
   "source": [
    "The auxiliary data corresponds to $\\tau b$ in the formula above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27733ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.auxdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b8e68",
   "metadata": {},
   "source": [
    "It's given by our background uncertainty `delta_b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3797cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b ** 2 / (delta_b ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd447826",
   "metadata": {},
   "source": [
    "To get the p-value for rejection of the background only hypothesis, we call `pyhf.infer.hypotest` with the test value 0 of our POI $\\mu$ using the `q0` test statistic.\n",
    "\n",
    "We want to know which p-value we would get if we would observe an excess of events of precisely the expected signal, so we plug in `s + b` for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = pyhf.infer.hypotest(\n",
    "    poi_test=0,\n",
    "    data=[s + b] + model.config.auxdata,\n",
    "    pdf=model,\n",
    "    test_stat=\"q0\"\n",
    ")\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124ca82",
   "metadata": {},
   "source": [
    "We can convert this into a significance (number of standard deviations) using the inverse of the cumulative standard normal distribution $\\Phi$. Note: for most implementations $z = -\\Phi^{-1}(p)$ is more numerically stable than $z = \\Phi^{-1}(1 - p)$ for small p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvalue_to_significance(pvalue):\n",
    "    return - stats.norm.ppf(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad12b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_to_significance(pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74082b10",
   "metadata": {},
   "source": [
    "That would not count as \"Evidence\" yet.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Exercise 7b:</b> How much excess events would we need to observe in our search region (assuming unchanged expected background) that we have potential for finding evidence (3 $\\sigma$) of a new signal?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713f24a",
   "metadata": {},
   "source": [
    "Equivalently we can test for exclusion and calculate $CL_s$. For that we use 1 as the test value for $\\mu$ and the `qtilde` test statistic.\n",
    "\n",
    "We want to know if we could exclude a signal if we would not observe any more data than our background expectation, so we set our data to `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38991cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLs = pyhf.infer.hypotest(\n",
    "    poi_test=1,\n",
    "    data=[b] + model.config.auxdata,\n",
    "    pdf=model,\n",
    "    test_stat=\"qtilde\"\n",
    ")\n",
    "CLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa98186",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question 7c:</b> Would that signal count as excluded?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ea2e8",
   "metadata": {},
   "source": [
    "## Run an upper limit scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c7091",
   "metadata": {},
   "source": [
    "## Run a scan in a signal grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
